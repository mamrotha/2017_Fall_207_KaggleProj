{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This tells matplotlib not to try opening a new window for each plot.\n",
    "%matplotlib inline\n",
    "\n",
    "# General libraries.\n",
    "import re\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# SK-learn libraries for learning.\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "# SK-learn libraries for evaluation.\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# SK-learn library for importing the newsgroup data.\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "# SK-learn libraries for feature extraction from text.\n",
    "from sklearn.feature_extraction.text import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Julia sample code\n",
    "using DataFrames\n",
    "using MachineLearning\n",
    "using JSON\n",
    "\n",
    "function read_data(file_name)\n",
    "    f = open(file_name)\n",
    "    json = JSON.parse(readall(f))\n",
    "    close(f)\n",
    "\n",
    "    colnames = keys(json[1])\n",
    "    columns  = Any[[json[i][name] for i=1:length(json)] for name=colnames]\n",
    "    DataFrame(columns, Symbol[name for name=colnames])\n",
    "end\n",
    "\n",
    "train = read_data(\"../data/train.json\")\n",
    "test  = read_data(\"../data/test.json\")\n",
    "\n",
    "println(@sprintf(\"There are %d rows in the training set\", nrow(train)))\n",
    "println(@sprintf(\"There are %d rows in the test set\", nrow(test)))\n",
    "\n",
    "feature_names = Symbol[\"requester_account_age_in_days_at_request\",\n",
    "                       \"requester_days_since_first_post_on_raop_at_request\",\n",
    "                       \"requester_number_of_comments_at_request\",\n",
    "                       \"requester_number_of_comments_in_raop_at_request\",\n",
    "                       \"requester_number_of_posts_at_request\",\n",
    "                       \"requester_number_of_posts_on_raop_at_request\",\n",
    "                       \"requester_number_of_subreddits_at_request\",\n",
    "                       \"requester_upvotes_minus_downvotes_at_request\",\n",
    "                       \"requester_upvotes_plus_downvotes_at_request\",\n",
    "                       \"unix_timestamp_of_request_utc\"]\n",
    "\n",
    "for feature = feature_names\n",
    "    train[feature] = float64(train[feature])\n",
    "    test[feature]  = float64(test[feature])\n",
    "end\n",
    "\n",
    "columns_to_keep = cat(1, feature_names, [:requester_received_pizza])\n",
    "\n",
    "rf = fit(train[columns_to_keep], :requester_received_pizza, classification_forest_options(num_trees=200, display=true))\n",
    "println(\"\")\n",
    "println(rf)\n",
    "println(\"\")\n",
    "predictions = predict_probs(rf, test)[:,2]\n",
    "submission = DataFrame(request_id=test[:request_id], requester_received_pizza=predictions)\n",
    "writetable(\"simple_julia_benchmark.csv\", submission)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../data/train.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-13b338ca702e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Load Data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mtrain_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"../data/train.json\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Train len:\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mtest_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"../data/test.json\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../data/train.json'"
     ]
    }
   ],
   "source": [
    "#json libraries\n",
    "import os\n",
    "import json\n",
    "\n",
    "# Load Data\n",
    "train_data = json.load(open(\"../data/train.json\"))\n",
    "print(\"Train len:\",len(train_data))\n",
    "test_data = json.load(open(\"../data/test.json\"))\n",
    "print(\"Test len:\",len(test_data))\n",
    "print(type(train_data[0]))\n",
    "print(\"Train example:\\n\",train_data[2])\n",
    "print(\"Test example:\\n\",test_data[8])\n",
    "\n",
    "# split train set into train and development for initial testing before submitting final predictions on test.json\n",
    "\n",
    "# DATA SUMMARY:\n",
    "# list of dictionaries\n",
    "# 'request_id' - sample point identifier, for final submission\n",
    "# 'requester_received_pizza' - boolean True, False\n",
    "# 'request_text' - raw text request, not always populated\n",
    "# 'request_text_edit_aware' - with \"edit\" comment removed, e.g. \"thanks for pizza\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4040 4040\n",
      "['Hi I am in need of food for my 4 children we are a military family that has really hit hard times and we have exahusted all means of help just to be able to feed my family and make it through another night is all i ask i know our blessing is coming so whatever u can find in your heart to give is greatly appreciated', 'I spent the last money I had on gas today. Im broke until next Thursday :('] \n",
      " [False, False]\n",
      "1631\n"
     ]
    }
   ],
   "source": [
    "# pull raw text and labels from train and test\n",
    "train_raw_text_list = []\n",
    "train_labels = []\n",
    "\n",
    "test_raw_text_list = []\n",
    "\n",
    "for ob in train_data:\n",
    "    #print(type(ob))\n",
    "    train_raw_text_list.append(ob['request_text_edit_aware'])\n",
    "    train_labels.append(ob['requester_received_pizza'])\n",
    "print(len(train_raw_text_list), len(train_labels))\n",
    "print(train_raw_text_list[0:2], \"\\n\", train_labels[0:2])\n",
    "\n",
    "for ob in test_data:\n",
    "    test_raw_text_list.append(ob['request_text_edit_aware'])\n",
    "print(len(test_raw_text_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(obs, features): (4040, 12317)\n",
      "Training set F1 score: 0.7656\n",
      "(1631,)\n",
      "[False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      "  True  True False False False False False False False False  True  True\n",
      " False False False  True False  True False False False  True False False\n",
      " False False]\n"
     ]
    }
   ],
   "source": [
    "#vectorize\n",
    "\n",
    "#preprocess\n",
    "def preprocessor(s):\n",
    "    s = s.lower()\n",
    "    return s\n",
    "\n",
    "#vectorize text\n",
    "vectorizer = CountVectorizer(preprocessor = preprocessor)\n",
    "train_text_feats = vectorizer.fit_transform(train_raw_text_list)\n",
    "print(\"(obs, features):\", train_text_feats.shape)\n",
    "\n",
    "#train Naive Bayes classifier\n",
    "nb = BernoulliNB()\n",
    "nb.fit(train_text_feats, train_labels)\n",
    "nb_train_preds = nb.predict(train_text_feats)\n",
    "train_f1_score = metrics.f1_score(train_labels, nb_train_preds, average='micro')\n",
    "print(\"Training set F1 score:\", \"{:.4}\".format(train_f1_score))\n",
    "\n",
    "#predict on test dataset\n",
    "test_feats = vectorizer.transform(test_raw_text_list)\n",
    "nb_test_preds = nb.predict(test_feats)\n",
    "print(nb_test_preds.shape)\n",
    "print(nb_test_preds[0:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
